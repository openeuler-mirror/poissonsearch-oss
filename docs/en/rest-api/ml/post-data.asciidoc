[[ml-post-data]]
==== Post Data to Jobs

The post data API allows you to send data to an anomaly detection job for analysis.
The job must have been opened prior to sending data.

===== Request

`POST _xpack/ml/anomaly_detectors/<job_id>/_data --data-binary @<data-file.json>`

===== Description

File sizes are limited to 100 Mb, so if your file is larger,
then split it into multiple files and upload each one separately in sequential time order.
When running in real-time, it is generally recommended to arrange to perform
many small uploads, rather than queueing data to upload larger files.


IMPORTANT:  Data can only be accepted from a single connection.
			Do not attempt to access the data endpoint from different threads at the same time.
			Use a single connection synchronously to send data, close, flush or delete a single job.
			+
			It is not currently possible to post data to multiple jobs using wildcards or a comma separated list.

===== Path Parameters

`job_id` (required)::
		(+string+)    Identifier for the job

===== Request Body

`reset_start`::
		(+string+; default: ++null++) Specifies the start of the bucket resetting range

`reset_end`::
		(+string+; default: ++null++) Specifies the end of the bucket resetting range"

////
===== Responses


			200
			(EmptyResponse) The cluster has been successfully deleted
			404
			(BasicFailedReply) The cluster specified by {cluster_id} cannot be found (code: clusters.cluster_not_found)
			412
			(BasicFailedReply) The Elasticsearch cluster has not been shutdown yet (code: clusters.cluster_plan_state_error)

			The following example sends data from file `data-file.json` to a job called `my_analysis`.
////
===== Examples

The following example posts data from the farequote.json file to the `farequote` job:

[source,js]
--------------------------------------------------
$ curl -s -H "Content-type: application/json"
-X POST http:\/\/localhost:9200/_xpack/ml/anomaly_detectors/farequote --data-binary @farequote.json
--------------------------------------------------
// CONSOLE
// TEST[skip:todo]

When the data is sent, you receive information about the operational progress of the job.
For example:
----
{
	"job_id":"farequote",
	"processed_record_count":86275,
	"processed_field_count":172550,
	"input_bytes":8678202,
	"input_field_count":258825,
	"invalid_date_count":0,
	"missing_field_count":0,
	"out_of_order_timestamp_count":0,
	"empty_bucket_count":0,
	"sparse_bucket_count":0,
	"bucket_count":1440,
	"earliest_record_timestamp":1454803200000,
	"latest_record_timestamp":1455235196000,
	"last_data_time":1491436182038,
	"input_record_count":86275
}
----

For more information about these properties, see <<ml-jobcounts,Job Counts>>.

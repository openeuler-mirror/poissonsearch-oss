## Smoke tests for tokenizers included in the analysis-common module

"keyword":
    - do:
        indices.analyze:
          body:
            text:      Foo Bar!
            tokenizer: keyword
    - length:    { tokens: 1 }
    - match:     { tokens.0.token: Foo Bar! }

---
"nGram":
    - do:
        indices.analyze:
          body:
            text: good
            explain: true
            tokenizer:
              type: nGram
              min_gram: 2
              max_gram: 2
    - length: { detail.tokenizer.tokens: 3 }
    - match:  { detail.tokenizer.name: _anonymous_tokenizer }
    - match:  { detail.tokenizer.tokens.0.token: go }
    - match:  { detail.tokenizer.tokens.1.token: oo }
    - match:  { detail.tokenizer.tokens.2.token: od }
